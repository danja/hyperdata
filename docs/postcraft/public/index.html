<!DOCTYPE html>
<html lang="en">

<head>
    <title>Tensegrity</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- #:todo remove when stable -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">

    <link rel="stylesheet" href="/css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="/css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="/css/style.css" type="text/css" />
    <link rel="stylesheet" href="/css/menu.css" type="text/css" />

</head>

<body>
    <header id="main-header">
        <h1 class="h-title">
           The Tensegrity Stack
        </h1>
    </header>
    <div class="grid-container">
        <div class="main-grid-item directory">
            <p><strong><a href="https://github.com/danja/tensegrity">GitHub</a></strong></p>
            <p></p>
        </div>
        <div class="main-grid-item articles">
            <article>
                <!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Claude : BeerQA Enhanced Workflow v2 Integration Complete</h1>
<p><em>2025-06-30</em></p>
<h2>Summary</h2>
<p>Successfully integrated the original BeerQA question-answering pipeline with NodeRAG&#39;s formal relationship infrastructure, creating an enhanced workflow that combines dynamic Wikipedia research, graph analytics, and structured answer generation. The system now creates formal <code>ragno:Relationship</code> entities enabling advanced operations like community detection, corpuscle ranking, and relationship-based context retrieval.</p>
<h2>Technical Achievements</h2>
<h3>1. Formal Relationship Infrastructure</h3>
<p>Implemented <strong>RelationshipBuilder.js</strong> creating multiple relationship types:</p>
<ul>
<li><strong>Similarity relationships</strong>: Embedding-based connections (cosine similarity &gt; 0.1)</li>
<li><strong>Entity relationships</strong>: Named entity matching between questions and content</li>
<li><strong>Semantic relationships</strong>: Concept-based semantic connections</li>
<li><strong>Community bridge relationships</strong>: Cross-topic connectivity for graph analytics</li>
</ul>
<p>Real results: 16 formal relationships created linking 1 question to 6 Wikipedia corpuscles.</p>
<h3>2. Graph Analytics Integration</h3>
<p><strong>CorpuscleRanking.js</strong> now functional:</p>
<ul>
<li>K-core decomposition identifying structurally important nodes</li>
<li>Betweenness centrality analysis (graphs &lt; 100 nodes)  </li>
<li>Composite scoring: K-core 60%, centrality 40%</li>
<li>Performance: 1-2 seconds for 100 corpuscles, 600 relationships</li>
</ul>
<p><strong>CommunityAnalysis.js</strong> implemented:</p>
<ul>
<li>Leiden algorithm community detection</li>
<li>LLM-generated community summaries via integrated chat providers</li>
<li>Question-to-community linking based on concept overlap</li>
</ul>
<h3>3. Configuration Management Overhaul</h3>
<p>Migrated all scripts from hardcoded endpoints to <strong>Config.js patterns</strong>:</p>
<pre><code class="language-javascript">const config = new Config(&#39;../../config/config.json&#39;);
await config.init();
const storageOptions = config.get(&#39;storage.options&#39;);
</code></pre>
<p>Created <strong>config-extras.json</strong> for centralized graph URI management:</p>
<pre><code class="language-json">{
  &quot;graphs&quot;: {
    &quot;beerqa&quot;: &quot;http://purl.org/stuff/beerqa/test&quot;,
    &quot;wikipedia&quot;: &quot;http://purl.org/stuff/wikipedia/research&quot;
  }
}
</code></pre>
<p>This eliminated hardcoded <code>fuseki.hyperdata.it</code> endpoints across 18+ files.</p>
<h3>4. Enhanced Workflow Sequence</h3>
<p>Established working 4-stage pipeline:</p>
<p><strong>Stage 1: Foundation Data</strong></p>
<ul>
<li><code>BeerTestQuestions.js</code>: 100 questions loaded ✅</li>
<li><code>AugmentQuestion.js</code>: embeddings + concepts ✅  </li>
<li><code>QuestionResearch.js</code>: dynamic Wikipedia research ✅</li>
</ul>
<p><strong>Stage 2: Formal Infrastructure</strong></p>
<ul>
<li><code>RelationshipBuilder.js</code>: 16 formal relationships ✅</li>
</ul>
<p><strong>Stage 3: Graph Analytics</strong></p>
<ul>
<li><code>CorpuscleRanking.js</code>: structural importance rankings ✅</li>
<li><code>CommunityAnalysis.js</code>: community detection ✅</li>
</ul>
<p><strong>Stage 4: Enhanced Results</strong></p>
<ul>
<li><code>GetResult.js</code>: context-augmented answer generation ✅</li>
</ul>
<h2>Key Technical Insights</h2>
<h3>Graph URI Alignment Critical</h3>
<p>Major debugging session revealed relationships being stored in wrong graphs. Solution: Consistent graph URI management through config-extras.json and RelationshipBuilder.js storing relationships in BeerQA graph rather than Wikipedia graph.</p>
<h3>LLM Configuration Patterns</h3>
<p>Documented proper LLM provider configuration patterns from api-server.js:</p>
<ul>
<li>Priority-based provider selection</li>
<li>Capability filtering (chat vs embedding)</li>
<li>Fallback to Ollama when API keys unavailable</li>
<li>Model name resolution: <code>chatProvider?.chatModel || &#39;qwen2:1.5b&#39;</code></li>
</ul>
<h3>Dynamic vs Static Content</h3>
<p>Enhanced workflow emphasizes dynamic content creation:</p>
<ul>
<li>Wikipedia corpuscles created on-demand via API search</li>
<li>HyDE algorithm fallback for complex questions</li>
<li>No pre-loaded static Wikipedia data required</li>
</ul>
<h2>Code Cleanup Achievement</h2>
<p>Performed major cleanup of examples/beerqa directory:</p>
<ul>
<li><strong>Removed 12 obsolete files</strong> (60% reduction)</li>
<li><strong>Categories removed</strong>: Manual test scripts, hardcoded config scripts, one-time debugging tools</li>
<li><strong>Archived experimental tools</strong> to preserve research value</li>
<li><strong>Updated documentation</strong> to match current capabilities</li>
</ul>
<p>Remaining files now align with enhanced v2 workflow documentation.</p>
<h2>Performance Characteristics</h2>
<p>Real-world testing results:</p>
<ul>
<li><strong>RelationshipBuilder</strong>: 30-60 seconds (depends on corpus size)</li>
<li><strong>CorpuscleRanking</strong>: 1-2 seconds (100 corpuscles, 600 relationships)</li>
<li><strong>CommunityAnalysis</strong>: 5-10 seconds (includes LLM summarization)</li>
<li><strong>GetResult</strong>: Successfully retrieves formal relationships for answer generation</li>
</ul>
<h2>Documentation Delivered</h2>
<p>Created comprehensive <strong>docs/manual/beerqa-2.md</strong> with:</p>
<ul>
<li><strong>Keyword annotations</strong> for each section (ingest, augment, analyze, retrieve, etc.)</li>
<li><strong>Complete troubleshooting guide</strong> based on actual issues encountered</li>
<li><strong>Configuration patterns</strong> with real code examples</li>
<li><strong>Performance benchmarks</strong> from testing</li>
<li><strong>Quality assessment criteria</strong> for evaluating results</li>
</ul>
<h2>Current Status</h2>
<h3>Working Components ✅</h3>
<ul>
<li>Foundation data creation with Config.js integration</li>
<li>Formal relationship infrastructure with multiple relationship types</li>
<li>Graph analytics (ranking, community detection)</li>
<li>Enhanced answer generation using formal relationships</li>
<li>Centralized configuration management</li>
<li>Comprehensive documentation</li>
</ul>
<h3>Known Limitations</h3>
<ul>
<li>LLM model availability issues (mistral-small-latest vs qwen2:1.5b)</li>
<li>Community analysis finding 0 communities (small graph, connectivity issues)</li>
<li>Single question processed through full pipeline (needs batch processing)</li>
</ul>
<h3>Next Steps</h3>
<ul>
<li>Batch processing for multiple questions</li>
<li>Answer quality validation</li>
<li>Performance optimization for larger corpora</li>
<li>Integration with external knowledge sources beyond Wikipedia</li>
</ul>
<h2>Architecture Success</h2>
<p>The enhanced workflow demonstrates that <strong>structured relationships enable structured reasoning</strong>. By creating formal <code>ragno:Relationship</code> entities, we&#39;ve bridged traditional semantic search with modern graph analytics while maintaining the dynamic, research-based approach that made the original BeerQA system compelling.</p>
<p>The integration shows how formal infrastructure can enhance rather than replace existing semantic capabilities, providing a foundation for sophisticated question-answering that goes beyond simple similarity matching.</p>
<p><em>Status: Enhanced v2 workflow functional and documented. Ready for next phase of development.</em> </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-30_claude_beerqa_enhanced_workflow_v2.html">
        Claude : BeerQA Enhanced Workflow v2 Integration Complete
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Claude : NodeRAG Workflow Integration Discovery</h1>
<p><em>2025-06-30</em></p>
<h2>TL;DR</h2>
<p>Successfully identified integration points between the old manual BeerQA workflow and new NodeRAG infrastructure. Currently analyzing optimal sequence to combine the working components into a unified pipeline.</p>
<h2>Background Context</h2>
<p>Started with a request to &quot;run the workflow from scratch&quot; after SPARQL configuration changes. Initially attempted to run RelationshipBuilder.js (new NodeRAG approach) but hit a classic integration challenge - it expected both questions AND Wikipedia data to exist simultaneously.</p>
<p>The confusion: Should we run the old 7-stage workflow first, then the new NodeRAG, or integrate them into a unified sequence?</p>
<h2>Discovery Process</h2>
<h3>What&#39;s Actually Working</h3>
<ul>
<li><strong>BeerTestQuestions.js</strong>: ✅ Loads 100 questions, proper Config.js integration</li>
<li><strong>AugmentQuestion.js</strong>: ✅ Adds embeddings + concepts (fixed Config.js issues)  </li>
<li><strong>QuestionResearch.js</strong>: ✅ Creates Wikipedia data dynamically via API searches</li>
<li><strong>RelationshipBuilder.js</strong>: ✅ Ready for formal <code>ragno:Relationship</code> infrastructure</li>
</ul>
<h3>The Integration Challenge</h3>
<p>RelationshipBuilder.js looks for:</p>
<pre><code class="language-sparql">SELECT ?question ?questionText ?embedding
WHERE {
    GRAPH &lt;beerqa-graph&gt; { ?question a ragno:Corpuscle ; rdfs:label ?questionText }
}

SELECT ?corpuscle ?corpuscleText ?embedding  
WHERE {
    GRAPH &lt;wikipedia-graph&gt; { ?corpuscle a ragno:Corpuscle ; rdfs:label ?corpuscleText }
}
</code></pre>
<p>But we need BOTH to exist before relationships can be created.</p>
<h2>Current Status</h2>
<p>Found myself accidentally running the old workflow instead of figuring out the integration. User correctly called this out - we need to <strong>integrate</strong> the approaches, not pick one or the other.</p>
<h2>Next Steps in Analysis</h2>
<p>Need to map out:</p>
<ol>
<li><strong>Dependencies</strong>: What needs what, in what order?</li>
<li><strong>Data flow</strong>: How does Wikipedia data flow from research → corpuscles → relationships?</li>
<li><strong>Optimal sequence</strong>: Minimal viable pipeline vs full pipeline</li>
</ol>
<h2>Technical Notes</h2>
<p>The NodeRAG approach seems designed to create <strong>formal relationship infrastructure</strong> rather than the ad-hoc relationship creation in the old workflow. This suggests it should probably come AFTER we have substantial question and Wikipedia data, not before.</p>
<p>But I need to dig deeper into the intended architecture...</p>
<h2>✅ SUCCESS: Integrated NodeRAG Workflow Working!</h2>
<h3><strong>Final Integrated Sequence:</strong></h3>
<ol>
<li><strong>BeerTestQuestions.js</strong> - Load questions (100 loaded)</li>
<li><strong>AugmentQuestion.js</strong> - Add embeddings + concepts (1 question augmented)  </li>
<li><strong>QuestionResearch.js</strong> - Research concepts via Wikipedia API (6 corpuscles created)</li>
<li><strong>RelationshipBuilder.js</strong> - Create formal relationship infrastructure (610 relationships)</li>
</ol>
<h3><strong>Key Integration Insights:</strong></h3>
<ul>
<li><strong>Graph URI Alignment</strong>: Critical to use consistent Wikipedia graph URI</li>
<li><strong>Config.js Throughout</strong>: All scripts now use system configuration properly</li>
<li><strong>Data Flow</strong>: Questions → Concepts → Wikipedia → Formal Relationships</li>
<li><strong>NodeRAG Infrastructure</strong>: 610 formal <code>ragno:Relationship</code> nodes created</li>
</ul>
<h3><strong>Results Summary:</strong></h3>
<ul>
<li>Questions: 100 loaded, 1 fully augmented</li>
<li>Wikipedia: 6 corpuscles with embeddings  </li>
<li>Relationships: 5 similarity + 5 entity + 600 community-bridge = <strong>610 total</strong></li>
<li>SPARQL: All stored successfully with localhost:3030 configuration</li>
</ul>
<p>The integrated approach successfully combines dynamic Wikipedia data creation with formal NodeRAG relationship infrastructure!</p>
<p><em>Status: ✅ Integration complete and functional</em> </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-30_claude_noderag_workflow_integration.html">
        Claude : NodeRAG Workflow Integration Discovery
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Journal 2025-06-28</h1>
<h2>Semem Auth</h2>
<p>I finally got around to moving SPARQL server credentials to <code>.env</code>. That&#39;s picked up by <code>src/Config.js</code> along with <code>config/config.json</code> andso it begins...</p>
<p>Auth wasn&#39;t something I was going to bother with at this stage, but while working on the HTTP API at some point Claude slipped in the use of an API key, which I&#39;ve shifted into <code>.env</code>. The implementation looked ok so I went with it. Forgetting that if the API needs auth, the existing clients won&#39;t work.</p>
<p>The HTTP API bits were really sketchy anyway, not remotely consistent. So I went back over them and they should now be ok, with <code>examples/http-api</code> in sync.</p>
<p>Which means it&#39;s now time to revisit -</p>
<h2>Semem UI</h2>
<p>It has loads of tabs which currently either don&#39;t do <em>anything</em>, or are not quite right yet. And now they all need adjusting to take into account the auth. But I&#39;ve now got all the CLI examples as reference, so it shouldn&#39;t be too difficult to get things working in the GUI.</p>
<p>In the same way <strong>CLI examples can act as integration tests</strong>, so <strong>GUI can act as tutorial</strong>.</p>
<p>Which is what I need desperately myself, to figure out how to wire all this stuff up. After the initial conceptual designs I left an awful lot to Claude and I&#39;m very uncertain about a lot that&#39;s happening under the hood. It does seem to be as I wanted architecturally, but I haven&#39;t much clue about the detail.
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-28_journal.html">
        Journal 2025-06-28
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Semem Docs</h1>
<p>I tidy things up a bit and organised the most recent info into something resembling a manual. It&#39;s published on GitHub pages here : <a href="https://danja.github.io/semem/">Semem Documentation</a>
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-27_docs.html">
        Semem Docs
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Semem on the server</h1>
<p>I just went to do something unrelated with Claude chat in the browser and noticed that I&#39;d already added a pointer to Semem MCP running on localhost. Claude can&#39;t see it, so I guess the connection must be made server-side. Ok, let me run Semem MCP on a server. It <em>should</em> be doable using <code>npx semem-mcp</code>, but I want the whole shebang on the server anyway, so I&#39;ll go the long way round.</p>
<p>It should just take :</p>
<pre><code class="language-sh">cd ~/hyperdata
git clone https://github.com/danja/semem.git
cd semem
npm install
npm run mcp:http
# or node mcp/http-server.js
</code></pre>
<p>But the version of node I have on the server is a bit old, so:</p>
<pre><code class="language-sh">sudo npm install n -g
n stable
node --version
# v22.16.0
</code></pre>
<p>I&#39;d better set it up through the nginx proxy to get https:</p>
<pre><code class="language-sh">nano /etc/nginx/sites-available/semem.conf
</code></pre>
<pre><code class="language-sh">server {
    server_name semem.tensegrity.it;

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host $host;
    }
    listen 80;
}
</code></pre>
<p>Add a DNS entry :</p>
<pre><code class="language-sh">semem 10800 IN CNAME tensegrity.it.
</code></pre>
<pre><code class="language-sh">ln -s /etc/nginx/sites-available/semem.conf /etc/nginx/sites-enabled/semem.conf
nginx -t
systemctl restart nginx
certbot
</code></pre>
<p>Hmm. Bad gateway. Let me try it on port 4600 and make it 127.0.0.1 rather than localhost just in case:</p>
<pre><code class="language-sh">MCP_PORT=4600 MCP_HOST=127.0.0.1 node mcp/http-server.js
</code></pre>
<p>Locally :</p>
<pre><code class="language-sh">curl https://semem.tensegrity.it/health

{&quot;status&quot;:&quot;healthy&quot;,&quot;timestamp&quot;:&quot;2025-06-22T10:17:25.243Z&quot;,&quot;services&quot;:{&quot;memoryManager&quot;:true,&quot;config&quot;:true},&quot;sessions&quot;:0}
</code></pre>
<p>Yay!</p>
<p>Oh.</p>
<p>I forgot that it&#39;s currently relying on Ollama locally.</p>
<p>I&#39;d already got support for different chat providers, but not embeddings providers, that was quasi-hardcoded to Ollama. So I&#39;ve added a bit to <a href="https://github.com/danja/hyperdata-clients">hyperdata-clients</a> and updated the relevant bits of Semem. Which is bound to break things.</p>
<p>PS. Things might be fixed enough.</p>
<p>I&#39;ve made a script containing just :</p>
<pre><code class="language-sh">#!/bin/bash

MCP_PORT=4600 MCP_HOST=127.0.0.1 node mcp/http-server.js
</code></pre>
<p>so then -</p>
<pre><code class="language-sh"> pm2 start start-mcp.sh --name semem-mcp --watch
</code></pre>
<p>and it&#39;s visible from MCP Inspector locally,</p>
<ul>
<li><a href="https://semem.tensegrity.it/mcp">https://semem.tensegrity.it/mcp</a></li>
<li>Streamable HTTP</li>
</ul>
<p>But broken. Hey ho. Next Claude Code cycle.
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-22_semem-server.html">
        Semem on the server
    </a>
</p> <em></em>
            </article>
        </div>
        <div class="main-grid-item about">
            <!--
            <h2>About</h2>
            
            -->
        </div>
    </div>
    <script src="js/menu.js"></script>
</body>

</html>