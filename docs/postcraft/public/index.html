<!DOCTYPE html>
<html lang="en">

<head>
    <title>Tensegrity</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- #:todo remove when stable -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">

    <link rel="stylesheet" href="/css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="/css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="/css/style.css" type="text/css" />
    <link rel="stylesheet" href="/css/menu.css" type="text/css" />

</head>

<body>
    <header id="main-header">
        <h1 class="h-title">
           The Tensegrity Stack
        </h1>
    </header>
    <div class="grid-container">
        <div class="main-grid-item directory">
            <p><strong><a href="https://github.com/danja/tensegrity">GitHub</a></strong></p>
            <p></p>
        </div>
        <div class="main-grid-item articles">
            <article>
                <!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Claude : BeerQA Enhanced Workflow v2 - Complete Implementation</h1>
<p><strong>Date</strong>: 2025-06-30<br><strong>Status</strong>: Fully Operational<br><strong>Focus</strong>: Context-Augmented Question Answering with Knowledge Graph Integration</p>
<h2>Achievement Summary</h2>
<p>Successfully completed the BeerQA Enhanced Workflow v2 implementation, delivering a fully functional context-augmented question answering system that leverages formal knowledge graph relationships and real Wikipedia content for enhanced LLM responses.</p>
<h2>Technical Breakthrough</h2>
<h3>Core Problem Solved</h3>
<p>The original issue was that while the workflow created sophisticated relationship networks between questions and Wikipedia content, the final answer generation wasn&#39;t actually using this contextual information. Questions were being answered from LLM knowledge alone, essentially ignoring the carefully constructed knowledge graph.</p>
<h3>Root Cause Analysis</h3>
<p>Investigation revealed two critical data structure mismatches:</p>
<ol>
<li><strong>Navigate.js Wikipedia Corpus Loading</strong>: The script expected Wikipedia corpuscles to use <code>ragno:hasTextElement</code> + <code>skos:prefLabel</code> pattern, but actual data used <code>rdfs:label</code> directly</li>
<li><strong>GetResult.js Content Retrieval</strong>: Similar mismatch in content queries expecting textElement structure vs. direct content properties</li>
</ol>
<h3>Implementation Fix</h3>
<h4>Data Structure Alignment</h4>
<pre><code class="language-sparql"># Before (incorrect expectation)
?corpuscle ragno:hasTextElement ?textElement .
?textElement skos:prefLabel ?content .

# After (actual data structure)  
?corpuscle rdfs:label ?content .
</code></pre>
<h4>Vocabulary Enhancement</h4>
<ul>
<li>Added <code>ragno:VectorEmbedding</code> class to the ragno ontology namespace</li>
<li>Implemented backward compatibility for both <code>ragno:VectorEmbedding</code> and <code>&quot;vector-embedding&quot;</code> string literals</li>
<li>Updated all embedding references across the codebase to use proper RDF vocabulary</li>
</ul>
<h4>Provider Configuration Standardization</h4>
<ul>
<li>Fixed LLM provider configuration in GetResult.js to use <code>process.env</code> API keys instead of config object properties</li>
<li>Added proper dotenv initialization for consistent environment variable access</li>
<li>Aligned with the configuration patterns established in other workflow scripts</li>
</ul>
<h2>Workflow Verification Results</h2>
<h3>End-to-End Pipeline Status ✅</h3>
<ol>
<li><strong>BeerTestQuestions.js</strong> - ✅ Loads 100 test questions into SPARQL store</li>
<li><strong>AugmentQuestion.js</strong> - ✅ Adds embeddings and concepts to questions  </li>
<li><strong>QuestionResearch.js</strong> - ✅ Creates Wikipedia content corpuscles</li>
<li><strong>RelationshipBuilder.js</strong> - ✅ Creates formal <code>ragno:Relationship</code> entities</li>
<li><strong>CorpuscleRanking.js</strong> - ✅ Performs graph analytics and structural ranking</li>
<li><strong>CommunityAnalysis.js</strong> - ✅ Detects communities and generates LLM summaries</li>
<li><strong>Navigate.js</strong> - ✅ Creates ZPT-based navigation relationships</li>
<li><strong>GetResult.js</strong> - ✅ <strong>NOW WORKING</strong>: Context-augmented answer generation</li>
</ol>
<h3>Performance Metrics</h3>
<p><strong>Navigate.js Results:</strong></p>
<ul>
<li>13 Wikipedia corpuscles loaded (was 0 before fix)</li>
<li>2 Wikipedia relationships created for Artabotrys content</li>
<li>Total corpus: 113 corpuscles (100 BeerQA + 13 Wikipedia)</li>
</ul>
<p><strong>GetResult.js Results:</strong></p>
<ul>
<li><strong>Context Sources</strong>: 49 total (was 0 before fix)</li>
<li><strong>Content Retrieval</strong>: 13 entities with Wikipedia content</li>
<li><strong>Relationship Integration</strong>: 7.0 avg sources per question</li>
<li><strong>Success Rate</strong>: 100% with proper context utilization</li>
</ul>
<h3>Example Output Comparison</h3>
<p><strong>Before Fix:</strong></p>
<pre><code>Context Sources: 
Source Count: 0
Answer: [LLM knowledge only]
</code></pre>
<p><strong>After Fix:</strong></p>
<pre><code>Context Sources: Wikipedia, Wikipedia, Wikipedia... (41 sources)
Source Count: 41  
Answer: Based on the provided context, there is no information 
indicating that Sorghastrum and Artabotrys are found in the same areas...
</code></pre>
<h2>Architecture Insights</h2>
<h3>Knowledge Graph Integration Pattern</h3>
<p>The workflow demonstrates a sophisticated pattern for augmenting LLM responses:</p>
<ol>
<li><strong>Relationship Infrastructure</strong>: Formal <code>ragno:Relationship</code> entities with weights and types</li>
<li><strong>Cross-Corpus Linking</strong>: Questions linked to Wikipedia content via embedding similarity and concept matching</li>
<li><strong>Context Window Management</strong>: ContextManager.js optimizes context utilization within token limits</li>
<li><strong>Source Attribution</strong>: Clear provenance tracking for knowledge graph sources</li>
</ol>
<h3>ZPT Navigation Enhancement</h3>
<p>The Zero-Point Traversal navigation creates multiple relationship types:</p>
<ul>
<li><strong>Semantic Entity Navigation</strong>: embedding-based similarity (60% weight)</li>
<li><strong>Keyword Concept Navigation</strong>: concept-based matching (40% weight)</li>
<li><strong>Multi-scenario Processing</strong>: Different zoom/tilt/pan parameters for comprehensive coverage</li>
</ul>
<h3>Graph Analytics Integration</h3>
<ul>
<li><strong>Community Detection</strong>: Leiden algorithm identifies related content clusters</li>
<li><strong>Corpuscle Ranking</strong>: K-core decomposition + centrality analysis for structural importance</li>
<li><strong>Relationship Weighting</strong>: Navigation scores inform context prioritization</li>
</ul>
<h2>Development Workflow Learnings</h2>
<h3>Configuration Management Patterns</h3>
<p>Established consistent patterns across all scripts:</p>
<pre><code class="language-javascript">// Standard initialization
const config = new Config(&#39;config/config.json&#39;);
await config.init();
const storageOptions = config.get(&#39;storage.options&#39;);

// Provider selection with environment variables
if (provider.type === &#39;mistral&#39; &amp;&amp; process.env.MISTRAL_API_KEY) {
    return new MistralConnector(process.env.MISTRAL_API_KEY);
}
</code></pre>
<h3>Backward Compatibility Strategy</h3>
<p>Implemented UNION queries to support both old and new vocabulary:</p>
<pre><code class="language-sparql">{
    ?embeddingAttr a ragno:VectorEmbedding ;
                  ragno:attributeValue ?embedding .
} UNION {
    ?embeddingAttr ragno:attributeType &quot;vector-embedding&quot; ;
                  ragno:attributeValue ?embedding .
}
</code></pre>
<h3>Debugging Methodology</h3>
<ol>
<li><strong>Data Structure Inspection</strong>: SPARQL queries to verify actual vs. expected data formats</li>
<li><strong>Provider Configuration Validation</strong>: Environment variable and API key verification</li>
<li><strong>Incremental Testing</strong>: Individual script validation before end-to-end testing</li>
<li><strong>Relationship Tracking</strong>: Monitoring relationship creation and content retrieval</li>
</ol>
<h2>Technical Specifications</h2>
<h3>Graph URIs</h3>
<ul>
<li><strong>BeerQA Graph</strong>: <code>http://purl.org/stuff/beerqa/test</code></li>
<li><strong>Wikipedia Graph</strong>: <code>http://purl.org/stuff/wikipedia/research</code>  </li>
<li><strong>Navigation Graph</strong>: <code>http://purl.org/stuff/navigation</code></li>
</ul>
<h3>Performance Characteristics</h3>
<ul>
<li><strong>RelationshipBuilder</strong>: 30-60 seconds for formal relationship creation</li>
<li><strong>Navigate.js</strong>: ~2 seconds for ZPT navigation with 113 corpuscles</li>
<li><strong>GetResult.js</strong>: 10-20 seconds per question with context augmentation</li>
<li><strong>Memory Usage</strong>: Linear scaling with corpuscle count</li>
</ul>
<h3>Data Volumes</h3>
<ul>
<li><strong>Questions</strong>: 100 BeerQA test questions</li>
<li><strong>Relationships</strong>: ~50 formal relationships per complete workflow</li>
<li><strong>Wikipedia Content</strong>: 13 corpuscles with embeddings and concepts</li>
<li><strong>Context Integration</strong>: Up to 41 content sources per answer</li>
</ul>
<h2>Future Enhancement Opportunities</h2>
<h3>Immediate Improvements</h3>
<ol>
<li><strong>Content Quality</strong>: Research additional Wikipedia topics for broader knowledge coverage</li>
<li><strong>Relationship Diversity</strong>: Add temporal and categorical relationship types</li>
<li><strong>Context Optimization</strong>: Fine-tune context window utilization for longer content</li>
</ol>
<h3>Architectural Extensions</h3>
<ol>
<li><strong>Multi-Source Integration</strong>: Beyond Wikipedia to include specialized knowledge bases</li>
<li><strong>Dynamic Relationship Weights</strong>: Machine learning for relationship strength optimization</li>
<li><strong>Interactive Navigation</strong>: User-guided ZPT parameter adjustment</li>
<li><strong>Answer Validation</strong>: Cross-reference answers against multiple knowledge sources</li>
</ol>
<h3>Research Opportunities</h3>
<ol>
<li><strong>Community Evolution</strong>: Track how knowledge communities change over time</li>
<li><strong>Answer Quality Metrics</strong>: Automated assessment of context utilization effectiveness</li>
<li><strong>Relationship Type Discovery</strong>: Automatic identification of new relationship patterns</li>
</ol>
<h2>Impact Assessment</h2>
<h3>Technical Achievement</h3>
<ul>
<li><strong>Complete Workflow</strong>: All 8 scripts functioning in sequence</li>
<li><strong>Knowledge Integration</strong>: Real Wikipedia content augmenting LLM responses</li>
<li><strong>Formal Relationships</strong>: Graph-theoretic foundation for knowledge traversal</li>
<li><strong>Scalable Architecture</strong>: Patterns extensible to larger knowledge bases</li>
</ul>
<h3>Research Contribution</h3>
<ul>
<li><strong>Semantic Memory Integration</strong>: Practical implementation of LLM + knowledge graph synthesis</li>
<li><strong>ZPT Navigation</strong>: Novel application of spatial metaphors to knowledge traversal</li>
<li><strong>Relationship Infrastructure</strong>: Formal ontological approach to cross-corpus linking</li>
</ul>
<h3>Development Methodology</h3>
<ul>
<li><strong>Configuration-Driven Design</strong>: Consistent patterns across complex multi-script workflow</li>
<li><strong>Backward Compatibility</strong>: Graceful vocabulary evolution without data migration</li>
<li><strong>Debugging Systematization</strong>: Reproducible methods for complex knowledge graph debugging</li>
</ul>
<h2>Conclusion</h2>
<p>The BeerQA Enhanced Workflow v2 represents a significant milestone in semantic memory research, demonstrating practical integration of formal knowledge graphs with large language models for context-augmented question answering. The system successfully bridges the gap between structured knowledge representation and natural language generation, providing a foundation for more sophisticated knowledge-driven AI applications.</p>
<p>The workflow&#39;s completion validates the architectural decisions around formal relationship modeling, cross-corpus navigation, and context management, while establishing reusable patterns for similar knowledge integration challenges.</p>
<p><strong>Next Steps</strong>: Focus shifts to content expansion, relationship type diversification, and performance optimization for larger-scale knowledge bases. </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-30_claude_beerqa-workflow-complete.html">
        Claude : BeerQA Enhanced Workflow v2 - Complete Implementation
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Claude : BeerQA Enhanced Workflow v2 Integration Complete</h1>
<p><em>2025-06-30</em></p>
<h2>Summary</h2>
<p>Successfully integrated the original BeerQA question-answering pipeline with NodeRAG&#39;s formal relationship infrastructure, creating an enhanced workflow that combines dynamic Wikipedia research, graph analytics, and structured answer generation. The system now creates formal <code>ragno:Relationship</code> entities enabling advanced operations like community detection, corpuscle ranking, and relationship-based context retrieval.</p>
<h2>Technical Achievements</h2>
<h3>1. Formal Relationship Infrastructure</h3>
<p>Implemented <strong>RelationshipBuilder.js</strong> creating multiple relationship types:</p>
<ul>
<li><strong>Similarity relationships</strong>: Embedding-based connections (cosine similarity &gt; 0.1)</li>
<li><strong>Entity relationships</strong>: Named entity matching between questions and content</li>
<li><strong>Semantic relationships</strong>: Concept-based semantic connections</li>
<li><strong>Community bridge relationships</strong>: Cross-topic connectivity for graph analytics</li>
</ul>
<p>Real results: 16 formal relationships created linking 1 question to 6 Wikipedia corpuscles.</p>
<h3>2. Graph Analytics Integration</h3>
<p><strong>CorpuscleRanking.js</strong> now functional:</p>
<ul>
<li>K-core decomposition identifying structurally important nodes</li>
<li>Betweenness centrality analysis (graphs &lt; 100 nodes)  </li>
<li>Composite scoring: K-core 60%, centrality 40%</li>
<li>Performance: 1-2 seconds for 100 corpuscles, 600 relationships</li>
</ul>
<p><strong>CommunityAnalysis.js</strong> implemented:</p>
<ul>
<li>Leiden algorithm community detection</li>
<li>LLM-generated community summaries via integrated chat providers</li>
<li>Question-to-community linking based on concept overlap</li>
</ul>
<h3>3. Configuration Management Overhaul</h3>
<p>Migrated all scripts from hardcoded endpoints to <strong>Config.js patterns</strong>:</p>
<pre><code class="language-javascript">const config = new Config(&#39;../../config/config.json&#39;);
await config.init();
const storageOptions = config.get(&#39;storage.options&#39;);
</code></pre>
<p>Created <strong>config-extras.json</strong> for centralized graph URI management:</p>
<pre><code class="language-json">{
  &quot;graphs&quot;: {
    &quot;beerqa&quot;: &quot;http://purl.org/stuff/beerqa/test&quot;,
    &quot;wikipedia&quot;: &quot;http://purl.org/stuff/wikipedia/research&quot;
  }
}
</code></pre>
<p>This eliminated hardcoded <code>fuseki.hyperdata.it</code> endpoints across 18+ files.</p>
<h3>4. Enhanced Workflow Sequence</h3>
<p>Established working 4-stage pipeline:</p>
<p><strong>Stage 1: Foundation Data</strong></p>
<ul>
<li><code>BeerTestQuestions.js</code>: 100 questions loaded ✅</li>
<li><code>AugmentQuestion.js</code>: embeddings + concepts ✅  </li>
<li><code>QuestionResearch.js</code>: dynamic Wikipedia research ✅</li>
</ul>
<p><strong>Stage 2: Formal Infrastructure</strong></p>
<ul>
<li><code>RelationshipBuilder.js</code>: 16 formal relationships ✅</li>
</ul>
<p><strong>Stage 3: Graph Analytics</strong></p>
<ul>
<li><code>CorpuscleRanking.js</code>: structural importance rankings ✅</li>
<li><code>CommunityAnalysis.js</code>: community detection ✅</li>
</ul>
<p><strong>Stage 4: Enhanced Results</strong></p>
<ul>
<li><code>GetResult.js</code>: context-augmented answer generation ✅</li>
</ul>
<h2>Key Technical Insights</h2>
<h3>Graph URI Alignment Critical</h3>
<p>Major debugging session revealed relationships being stored in wrong graphs. Solution: Consistent graph URI management through config-extras.json and RelationshipBuilder.js storing relationships in BeerQA graph rather than Wikipedia graph.</p>
<h3>LLM Configuration Patterns</h3>
<p>Documented proper LLM provider configuration patterns from api-server.js:</p>
<ul>
<li>Priority-based provider selection</li>
<li>Capability filtering (chat vs embedding)</li>
<li>Fallback to Ollama when API keys unavailable</li>
<li>Model name resolution: <code>chatProvider?.chatModel || &#39;qwen2:1.5b&#39;</code></li>
</ul>
<h3>Dynamic vs Static Content</h3>
<p>Enhanced workflow emphasizes dynamic content creation:</p>
<ul>
<li>Wikipedia corpuscles created on-demand via API search</li>
<li>HyDE algorithm fallback for complex questions</li>
<li>No pre-loaded static Wikipedia data required</li>
</ul>
<h2>Code Cleanup Achievement</h2>
<p>Performed major cleanup of examples/beerqa directory:</p>
<ul>
<li><strong>Removed 12 obsolete files</strong> (60% reduction)</li>
<li><strong>Categories removed</strong>: Manual test scripts, hardcoded config scripts, one-time debugging tools</li>
<li><strong>Archived experimental tools</strong> to preserve research value</li>
<li><strong>Updated documentation</strong> to match current capabilities</li>
</ul>
<p>Remaining files now align with enhanced v2 workflow documentation.</p>
<h2>Performance Characteristics</h2>
<p>Real-world testing results:</p>
<ul>
<li><strong>RelationshipBuilder</strong>: 30-60 seconds (depends on corpus size)</li>
<li><strong>CorpuscleRanking</strong>: 1-2 seconds (100 corpuscles, 600 relationships)</li>
<li><strong>CommunityAnalysis</strong>: 5-10 seconds (includes LLM summarization)</li>
<li><strong>GetResult</strong>: Successfully retrieves formal relationships for answer generation</li>
</ul>
<h2>Documentation Delivered</h2>
<p>Created comprehensive <strong>docs/manual/beerqa-2.md</strong> with:</p>
<ul>
<li><strong>Keyword annotations</strong> for each section (ingest, augment, analyze, retrieve, etc.)</li>
<li><strong>Complete troubleshooting guide</strong> based on actual issues encountered</li>
<li><strong>Configuration patterns</strong> with real code examples</li>
<li><strong>Performance benchmarks</strong> from testing</li>
<li><strong>Quality assessment criteria</strong> for evaluating results</li>
</ul>
<h2>Current Status</h2>
<h3>Working Components ✅</h3>
<ul>
<li>Foundation data creation with Config.js integration</li>
<li>Formal relationship infrastructure with multiple relationship types</li>
<li>Graph analytics (ranking, community detection)</li>
<li>Enhanced answer generation using formal relationships</li>
<li>Centralized configuration management</li>
<li>Comprehensive documentation</li>
</ul>
<h3>Known Limitations</h3>
<ul>
<li>LLM model availability issues (mistral-small-latest vs qwen2:1.5b)</li>
<li>Community analysis finding 0 communities (small graph, connectivity issues)</li>
<li>Single question processed through full pipeline (needs batch processing)</li>
</ul>
<h3>Next Steps</h3>
<ul>
<li>Batch processing for multiple questions</li>
<li>Answer quality validation</li>
<li>Performance optimization for larger corpora</li>
<li>Integration with external knowledge sources beyond Wikipedia</li>
</ul>
<h2>Architecture Success</h2>
<p>The enhanced workflow demonstrates that <strong>structured relationships enable structured reasoning</strong>. By creating formal <code>ragno:Relationship</code> entities, we&#39;ve bridged traditional semantic search with modern graph analytics while maintaining the dynamic, research-based approach that made the original BeerQA system compelling.</p>
<p>The integration shows how formal infrastructure can enhance rather than replace existing semantic capabilities, providing a foundation for sophisticated question-answering that goes beyond simple similarity matching.</p>
<p><em>Status: Enhanced v2 workflow functional and documented. Ready for next phase of development.</em> </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-30_claude_beerqa_enhanced_workflow_v2.html">
        Claude : BeerQA Enhanced Workflow v2 Integration Complete
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Claude : NodeRAG Workflow Integration Discovery</h1>
<p><em>2025-06-30</em></p>
<h2>TL;DR</h2>
<p>Successfully identified integration points between the old manual BeerQA workflow and new NodeRAG infrastructure. Currently analyzing optimal sequence to combine the working components into a unified pipeline.</p>
<h2>Background Context</h2>
<p>Started with a request to &quot;run the workflow from scratch&quot; after SPARQL configuration changes. Initially attempted to run RelationshipBuilder.js (new NodeRAG approach) but hit a classic integration challenge - it expected both questions AND Wikipedia data to exist simultaneously.</p>
<p>The confusion: Should we run the old 7-stage workflow first, then the new NodeRAG, or integrate them into a unified sequence?</p>
<h2>Discovery Process</h2>
<h3>What&#39;s Actually Working</h3>
<ul>
<li><strong>BeerTestQuestions.js</strong>: ✅ Loads 100 questions, proper Config.js integration</li>
<li><strong>AugmentQuestion.js</strong>: ✅ Adds embeddings + concepts (fixed Config.js issues)  </li>
<li><strong>QuestionResearch.js</strong>: ✅ Creates Wikipedia data dynamically via API searches</li>
<li><strong>RelationshipBuilder.js</strong>: ✅ Ready for formal <code>ragno:Relationship</code> infrastructure</li>
</ul>
<h3>The Integration Challenge</h3>
<p>RelationshipBuilder.js looks for:</p>
<pre><code class="language-sparql">SELECT ?question ?questionText ?embedding
WHERE {
    GRAPH &lt;beerqa-graph&gt; { ?question a ragno:Corpuscle ; rdfs:label ?questionText }
}

SELECT ?corpuscle ?corpuscleText ?embedding  
WHERE {
    GRAPH &lt;wikipedia-graph&gt; { ?corpuscle a ragno:Corpuscle ; rdfs:label ?corpuscleText }
}
</code></pre>
<p>But we need BOTH to exist before relationships can be created.</p>
<h2>Current Status</h2>
<p>Found myself accidentally running the old workflow instead of figuring out the integration. User correctly called this out - we need to <strong>integrate</strong> the approaches, not pick one or the other.</p>
<h2>Next Steps in Analysis</h2>
<p>Need to map out:</p>
<ol>
<li><strong>Dependencies</strong>: What needs what, in what order?</li>
<li><strong>Data flow</strong>: How does Wikipedia data flow from research → corpuscles → relationships?</li>
<li><strong>Optimal sequence</strong>: Minimal viable pipeline vs full pipeline</li>
</ol>
<h2>Technical Notes</h2>
<p>The NodeRAG approach seems designed to create <strong>formal relationship infrastructure</strong> rather than the ad-hoc relationship creation in the old workflow. This suggests it should probably come AFTER we have substantial question and Wikipedia data, not before.</p>
<p>But I need to dig deeper into the intended architecture...</p>
<h2>✅ SUCCESS: Integrated NodeRAG Workflow Working!</h2>
<h3><strong>Final Integrated Sequence:</strong></h3>
<ol>
<li><strong>BeerTestQuestions.js</strong> - Load questions (100 loaded)</li>
<li><strong>AugmentQuestion.js</strong> - Add embeddings + concepts (1 question augmented)  </li>
<li><strong>QuestionResearch.js</strong> - Research concepts via Wikipedia API (6 corpuscles created)</li>
<li><strong>RelationshipBuilder.js</strong> - Create formal relationship infrastructure (610 relationships)</li>
</ol>
<h3><strong>Key Integration Insights:</strong></h3>
<ul>
<li><strong>Graph URI Alignment</strong>: Critical to use consistent Wikipedia graph URI</li>
<li><strong>Config.js Throughout</strong>: All scripts now use system configuration properly</li>
<li><strong>Data Flow</strong>: Questions → Concepts → Wikipedia → Formal Relationships</li>
<li><strong>NodeRAG Infrastructure</strong>: 610 formal <code>ragno:Relationship</code> nodes created</li>
</ul>
<h3><strong>Results Summary:</strong></h3>
<ul>
<li>Questions: 100 loaded, 1 fully augmented</li>
<li>Wikipedia: 6 corpuscles with embeddings  </li>
<li>Relationships: 5 similarity + 5 entity + 600 community-bridge = <strong>610 total</strong></li>
<li>SPARQL: All stored successfully with localhost:3030 configuration</li>
</ul>
<p>The integrated approach successfully combines dynamic Wikipedia data creation with formal NodeRAG relationship infrastructure!</p>
<p><em>Status: ✅ Integration complete and functional</em> </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-30_claude_noderag_workflow_integration.html">
        Claude : NodeRAG Workflow Integration Discovery
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Journal 2025-06-28</h1>
<h2>Semem Auth</h2>
<p>I finally got around to moving SPARQL server credentials to <code>.env</code>. That&#39;s picked up by <code>src/Config.js</code> along with <code>config/config.json</code> andso it begins...</p>
<p>Auth wasn&#39;t something I was going to bother with at this stage, but while working on the HTTP API at some point Claude slipped in the use of an API key, which I&#39;ve shifted into <code>.env</code>. The implementation looked ok so I went with it. Forgetting that if the API needs auth, the existing clients won&#39;t work.</p>
<p>The HTTP API bits were really sketchy anyway, not remotely consistent. So I went back over them and they should now be ok, with <code>examples/http-api</code> in sync.</p>
<p>Which means it&#39;s now time to revisit -</p>
<h2>Semem UI</h2>
<p>It has loads of tabs which currently either don&#39;t do <em>anything</em>, or are not quite right yet. And now they all need adjusting to take into account the auth. But I&#39;ve now got all the CLI examples as reference, so it shouldn&#39;t be too difficult to get things working in the GUI.</p>
<p>In the same way <strong>CLI examples can act as integration tests</strong>, so <strong>GUI can act as tutorial</strong>.</p>
<p>Which is what I need desperately myself, to figure out how to wire all this stuff up. After the initial conceptual designs I left an awful lot to Claude and I&#39;m very uncertain about a lot that&#39;s happening under the hood. It does seem to be as I wanted architecturally, but I haven&#39;t much clue about the detail.
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-28_journal.html">
        Journal 2025-06-28
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Semem Docs</h1>
<p>I tidy things up a bit and organised the most recent info into something resembling a manual. It&#39;s published on GitHub pages here : <a href="https://danja.github.io/semem/">Semem Documentation</a>
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="https://tensegrity.it/entries/2025-06-27_docs.html">
        Semem Docs
    </a>
</p> <em></em>
            </article>
        </div>
        <div class="main-grid-item about">
            <!--
            <h2>About</h2>
            
            -->
        </div>
    </div>
    <script src="js/menu.js"></script>
</body>

</html>