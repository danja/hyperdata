<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hyperdata - Recent Articles</title>
  <id>https://hyperdata.it/atom.xml</id>
  <updated>2025-11-03T10:11:31.693Z</updated>
  <link href="https://hyperdata.it/atom.xml" rel="self" />
  <link href="https://hyperdata.it" />
  <subtitle>Latest articles from hyperdata</subtitle>
  <author>
    <name>Danny Ayers</name>
    <email>danny.ayers@gmail.com</email>
  </author>
  <entry>
    <title>Claude : Document Upload Timeout Resolution</title>
    <id>https://tensegrity.it/entries/2025-10-25_claude_document-upload-optimization</id>
    <updated>2025-10-25T12:03:09.606Z</updated>
    <link href="https://tensegrity.it/entries/2025-10-25_claude_document-upload-optimization" />
    <published>2025-10-25T12:03:09.606Z</published>
    <author>
      <name>Danny Ayers</name>
      <email>danny.ayers@gmail.com</email>
    </author>
    <content type="xhtml">
      <div xmlns="http://www.w3.org/1999/xhtml">
        <!-- ARTICLE CONTENT -->
        <article class="post-content">
            <h1>Claude : Document Upload Timeout Resolution</h1>
        <h2>Problem Statement</h2>
        <p>Document uploads from the Workbench UI were consistently timing out, even for small files. Investigation revealed two critical bottlenecks:</p>
        <h3>Root Causes</h3>
        <ol>
        <li><p><strong>HTTP Timeout Limitation</strong></p>
        <ul>
        <li>Express default timeout: 120 seconds (2 minutes)</li>
        <li>Document processing with embedding generation exceeded this limit</li>
        </ul>
        </li>
        <li><p><strong>Sequential Processing Bottleneck</strong></p>
        <ul>
        <li>Chunks processed one-by-one in a <code>for</code> loop</li>
        <li>Each chunk required:<ul>
        <li>Embedding generation: ~3-5 seconds</li>
        <li>Concept extraction: ~3-5 seconds</li>
        </ul>
        </li>
        <li>Example: 16-chunk document = ~96-160 seconds (sequential)</li>
        </ul>
        </li>
        </ol>
        <h2>Solutions Implemented</h2>
        <h3>1. Extended HTTP Timeout (<code>api-server.js:574-579</code>)</h3>
        <p>Added middleware to <code>/documents/upload</code> endpoint extending timeout to 10 minutes:</p>
        <pre><code class="language-javascript">apiRouter.post(&#39;/documents/upload&#39;,
            this.authenticateRequest,
            this.upload.single(&#39;file&#39;),
            (req, res, next) =&gt; {
                // Set timeout to 10 minutes (600000ms)
                req.setTimeout(600000);
                res.setTimeout(600000);
                next();
            },
            this.createDocumentHandler(&#39;document-api&#39;, &#39;upload&#39;)
        );
        </code></pre>
        <h3>2. Parallelized Chunk Processing (<code>DocumentAPI.js:582-648</code>)</h3>
        <p>Converted sequential processing to parallel execution using <code>Promise.all</code>:</p>
        <p><strong>Before (Sequential):</strong></p>
        <pre><code class="language-javascript">for (const chunk of chunks) {
            const embedding = await generateEmbedding(chunk);
            const concepts = await extractConcepts(chunk);
            await storeInMemory(chunk, embedding, concepts);
        }
        </code></pre>
        <p><strong>After (Parallel):</strong></p>
        <pre><code class="language-javascript">const chunkPromises = chunks.map(async (chunk) =&gt; {
            // Process embedding and concepts in parallel for each chunk
            const [embedding, concepts] = await Promise.all([
                generateEmbedding(chunk),
                extractConcepts(chunk)
            ]);
            await storeInMemory(chunk, embedding, concepts);
            return { interactionId, chunkUri, concepts: concepts.length };
        });
        // Process all chunks in parallel
        const results = await Promise.all(chunkPromises);
        </code></pre>
        <h2>Performance Improvements</h2>
        <h3>Before Optimization</h3>
        <ul>
        <li><strong>Small docs</strong> (1-5 chunks): 15-50 seconds ‚Üí <strong>timeout risk</strong></li>
        <li><strong>Medium docs</strong> (10-20 chunks): 96-160 seconds ‚Üí <strong>guaranteed timeout</strong></li>
        <li><strong>Large docs</strong> (50+ chunks): 480+ seconds ‚Üí <strong>impossible to upload</strong></li>
        </ul>
        <h3>After Optimization</h3>
        <ul>
        <li><strong>Small docs</strong> (1-5 chunks): ~5-15 seconds ‚úÖ</li>
        <li><strong>Medium docs</strong> (10-20 chunks): ~10-30 seconds ‚úÖ</li>
        <li><strong>Large docs</strong> (50+ chunks): ~30-120 seconds ‚úÖ</li>
        </ul>
        <p>All well within the 10-minute timeout window.</p>
        <h2>Test Results</h2>
        <h3>Test Document Upload</h3>
        <ul>
        <li><strong>File</strong>: test-upload.md (776 bytes)</li>
        <li><strong>Processing time</strong>: 1.566 seconds</li>
        <li><strong>Chunks created</strong>: 1</li>
        <li><strong>Concepts extracted</strong>: 9</li>
        <li><strong>Status</strong>: ‚úÖ Success</li>
        </ul>
        <h3>Processing Breakdown</h3>
        <ol>
        <li><strong>Conversion</strong>: Markdown ‚Üí Markdown (776 bytes)</li>
        <li><strong>Chunking</strong>: 1 semantic chunk created</li>
        <li><strong>Ingestion</strong>: 1 chunk stored in SPARQL</li>
        <li><strong>Memory</strong>: 1 interaction stored with embeddings</li>
        </ol>
        <h2>UI Impact</h2>
        <h3>Workbench Session Stats Enhancement</h3>
        <p>Also implemented during this session:</p>
        <ol>
        <li><p><strong>Fixed Element ID Mismatch</strong></p>
        <ul>
        <li>Updated JavaScript to reference correct HTML element IDs (<code>-bottom</code> suffix)</li>
        </ul>
        </li>
        <li><p><strong>Added Document/Chunk Stats</strong></p>
        <ul>
        <li>üí≠ Interactions count</li>
        <li>üß© Concepts count</li>
        <li>üìÑ Documents count (new!)</li>
        <li>üì¶ Chunks count (new!)</li>
        <li>‚ö° Session duration</li>
        </ul>
        </li>
        <li><p><strong>Improved Mobile Layout</strong></p>
        <ul>
        <li>Stats display horizontally in rows on mobile</li>
        <li>Proper wrapping with tighter spacing</li>
        <li>Smaller fonts and icons for compact display</li>
        </ul>
        </li>
        </ol>
        <h2>Technical Details</h2>
        <h3>Parallel Execution Benefits</h3>
        <ol>
        <li><strong>Within-Chunk Parallelization</strong>: Embedding + concept extraction happen simultaneously</li>
        <li><strong>Cross-Chunk Parallelization</strong>: All chunks process at the same time</li>
        <li><strong>Non-blocking</strong>: Server can handle multiple upload requests concurrently</li>
        </ol>
        <h3>Memory Safety</h3>
        <p>The parallel processing doesn&#39;t overwhelm memory because:</p>
        <ul>
        <li>Node.js event loop handles concurrency efficiently</li>
        <li>LLM/embedding providers have their own rate limiting</li>
        <li>Memory manager queues requests internally</li>
        </ul>
        <h2>Files Modified</h2>
        <ol>
        <li><code>src/servers/api-server.js</code> - Extended timeout for upload endpoint</li>
        <li><code>src/api/features/DocumentAPI.js</code> - Parallelized chunk processing</li>
        <li><code>src/frontend/workbench/public/js/workbench.js</code> - Fixed stats element IDs, added doc/chunk tracking</li>
        <li><code>src/frontend/workbench/public/js/services/StateManager.js</code> - Added doc/chunk counts to session state</li>
        <li><code>src/frontend/workbench/public/index.html</code> - Added doc/chunk stat display</li>
        <li><code>src/frontend/workbench/public/styles/workbench.css</code> - Compacted stats, fixed mobile layout</li>
        </ol>
        <h2>Conclusion</h2>
        <p>The document upload system is now highly responsive and reliable. The combination of extended timeouts and parallel processing ensures that even large documents can be uploaded, processed, and ingested without timeout failures. The workbench UI provides real-time feedback on upload progress through the enhanced session statistics.</p>
        <hr>
        <p><em>Generated: 2025-10-25</em>
        <em>Session: Document Upload Optimization</em>
         </p>
        </article>
        <p class="post-title h-cinzel">
            <a href="https://tensegrity.it/entries/2025-10-25_claude_document-upload-optimization.html">
                Claude : Document Upload Timeout Resolution
            </a>
        </p> <em></em>
      </div>
    </content>
  </entry>
  <entry>
    <title>Claude: VSOM Training Implementation - Making Self-Organizing Maps Useful</title>
    <id>https://tensegrity.it/entries/2025-10-02_claude_vsom-training-implementation</id>
    <updated>2025-10-02T13:51:24.962Z</updated>
    <link href="https://tensegrity.it/entries/2025-10-02_claude_vsom-training-implementation" />
    <published>2025-10-02T13:51:24.962Z</published>
    <author>
      <name>Danny Ayers</name>
      <email>danny.ayers@gmail.com</email>
    </author>
    <content type="xhtml">
      <div xmlns="http://www.w3.org/1999/xhtml">
        <!-- ARTICLE CONTENT -->
        <article class="post-content">
            <h1>Claude: VSOM Training Implementation - Making Self-Organizing Maps Useful</h1>
        <p><strong>Date:</strong> October 2, 2025
        <strong>Session:</strong> VSOM Training Feature Development
        <strong>Status:</strong> Implemented &amp; Ready for Testing</p>
        <h2>Overview</h2>
        <p>Implemented actual self-organizing map (SOM) training for the VSOM visualization interface, transforming it from a simple grid layout into a semantically meaningful spatial organization tool. The user&#39;s insight was spot-on: &quot;A Train button might be a good starting point?&quot;</p>
        <h2>Problem Identified</h2>
        <p>During investigation of the VSOM codebase, discovered a revealing comment in <code>DataProcessor.js</code> line 449:</p>
        <pre><code class="language-javascript">// In a real VSOM, this would involve training and similarity calculations
        </code></pre>
        <p>The VSOM visualization was using:</p>
        <ul>
        <li>Simple grid positioning (deterministic layout)</li>
        <li>Mock activation values (<code>Math.random() * 0.5 + 0.5</code>)</li>
        <li>Mock weight values (<code>Math.random() * 0.3 + 0.7</code>)</li>
        <li>No actual Kohonen SOM training algorithm</li>
        </ul>
        <h2>Key Discovery: Existing Infrastructure</h2>
        <p>Found comprehensive VSOM infrastructure already in place:</p>
        <ul>
        <li><strong><code>src/services/vsom/VSOMService.js</code></strong>: Full service layer with instance management, training coordination, clustering</li>
        <li><strong><code>src/ragno/algorithms/VSOM.js</code></strong>: Complete Kohonen SOM implementation with:<ul>
        <li>VSOMCore: Weight initialization, BMU finding, distance metrics</li>
        <li>VSOMTopology: Rectangular/hexagonal topologies, neighborhood calculations</li>
        <li>VSOMTraining: Iterative training with learning rate decay</li>
        </ul>
        </li>
        </ul>
        <p>This changed the implementation strategy from &quot;build SOM from scratch&quot; to &quot;wire existing backend to frontend.&quot;</p>
        <h2>Implementation</h2>
        <h3>1. Backend Integration</h3>
        <p><strong>Created <code>TrainVSOMCommand.js</code></strong> (src/mcp/tools/verbs/commands/):</p>
        <ul>
        <li>Wraps VSOMService for MCP verb interface</li>
        <li>Retrieves knowledge graph nodes with embeddings from SPARQL store</li>
        <li>Handles training lifecycle: create instance ‚Üí load data ‚Üí train ‚Üí get results</li>
        <li>Returns trained grid positions and cluster assignments</li>
        </ul>
        <p><strong>Added Training Endpoint</strong> (src/mcp/http-server.js:540-565):</p>
        <pre><code class="language-javascript">app.post(&#39;/train-vsom&#39;, async (req, res) =&gt; {
          const { epochs = 100, learningRate = 0.1, gridSize = 20 } = req.body;
          const trainingResult = await simpleVerbsService.execute(&#39;train-vsom&#39;, {
            epochs, learningRate, gridSize
          });
          res.json(trainingResult);
        });
        </code></pre>
        <p><strong>Registry Updates</strong>:</p>
        <ul>
        <li>Added <code>TrainVSOMSchema</code> to VerbSchemas.js with validation (epochs: 1-10000, learningRate: 0.001-1.0, gridSize: 5-50)</li>
        <li>Registered <code>TrainVSOMCommand</code> in VerbCommandRegistry.js</li>
        <li>Added &#39;train-vsom&#39; to SimpleVerbsService core tool names</li>
        </ul>
        <h3>2. Frontend Integration</h3>
        <p><strong>UI Enhancement</strong> (src/frontend/vsom-standalone/public/index.html):</p>
        <pre><code class="language-html">&lt;button class=&quot;control-button&quot; id=&quot;train-vsom&quot;&gt;
            &lt;span class=&quot;button-icon&quot;&gt;üß†&lt;/span&gt;
            Train Map
        &lt;/button&gt;
        </code></pre>
        <p><strong>API Service Method</strong> (VSOMApiService.js:232-271):</p>
        <pre><code class="language-javascript">async trainVSOM(options = {}) {
          const result = await this.makeRequest(&#39;/train-vsom&#39;, {
            method: &#39;POST&#39;,
            body: JSON.stringify({
              epochs, learningRate, gridSize
            })
          });
          return result;
        }
        </code></pre>
        <p><strong>Event Handler</strong> (vsom-standalone.js:728-779):</p>
        <pre><code class="language-javascript">async handleTrainVSOM() {
          this.showToast(&#39;Starting VSOM training...&#39;, &#39;info&#39;);
          const trainingResult = await this.services.api.trainVSOM({
            epochs: 100, learningRate: 0.1, gridSize: 20
          });
          if (trainingResult.success) {
            // Convert mappings to positioned nodes
            const trainedNodes = trainingResult.mappings.map(mapping =&gt; ({
              ...mapping.entity,
              x: mapping.mapPosition[0],
              y: mapping.mapPosition[1],
              trained: true
            }));
            this.components.grid.updateNodes(trainedNodes);
            this.showToast(
              `Training complete! ${trainingResult.metadata.entitiesCount} nodes organized`,
              &#39;success&#39;
            );
          }
        }
        </code></pre>
        <h2>Architecture Flow</h2>
        <ol>
        <li><strong>User clicks &quot;Train Map&quot; button</strong></li>
        <li><strong>Frontend</strong> ‚Üí <code>trainVSOM()</code> ‚Üí POST /train-vsom</li>
        <li><strong>MCP Server</strong> ‚Üí SimpleVerbsService.execute(&#39;train-vsom&#39;)</li>
        <li><strong>TrainVSOMCommand</strong>:<ul>
        <li>Queries SPARQL for entities with embeddings</li>
        <li>Creates VSOMService instance (20√ó20 grid, 1536-dim embeddings)</li>
        <li>Loads entities into VSOM</li>
        <li>Trains with Kohonen algorithm (100 epochs, learning rate 0.1‚Üí0.01)</li>
        <li>Returns grid positions and cluster info</li>
        </ul>
        </li>
        <li><strong>Frontend</strong> ‚Üê Receives trained positions</li>
        <li><strong>VSOMGrid</strong> ‚Üê Updates with spatially-organized node positions</li>
        </ol>
        <h2>Technical Details</h2>
        <h3>Training Parameters</h3>
        <ul>
        <li><strong>Grid Size</strong>: 20√ó20 (400 nodes)</li>
        <li><strong>Embedding Dimension</strong>: 1536 (nomic-embed-text)</li>
        <li><strong>Epochs</strong>: 100 (configurable 1-10000)</li>
        <li><strong>Learning Rate</strong>: 0.1 ‚Üí 0.01 (exponential decay)</li>
        <li><strong>Distance Metric</strong>: Cosine similarity</li>
        <li><strong>Topology</strong>: Rectangular with bounded conditions</li>
        </ul>
        <h3>Data Flow</h3>
        <ul>
        <li>Knowledge graph nodes retrieved from SPARQL store</li>
        <li>Only nodes with valid 1536-dimensional embeddings used</li>
        <li>Training finds Best Matching Unit (BMU) for each entity</li>
        <li>Neighborhood updates based on Gaussian function</li>
        <li>Result: Entities with similar embeddings cluster spatially</li>
        </ul>
        <h2>Benefits for End Users</h2>
        <p><strong>Before Training</strong>:</p>
        <ul>
        <li>Nodes arranged in arbitrary grid</li>
        <li>No semantic meaning to spatial proximity</li>
        <li>Manual organization required</li>
        </ul>
        <p><strong>After Training</strong>:</p>
        <ul>
        <li>Similar concepts naturally cluster together</li>
        <li>Spatial neighborhoods reflect semantic relationships</li>
        <li>Visual exploration reveals unexpected connections</li>
        <li>Quantitative quality metrics (quantization error, topographic error)</li>
        </ul>
        <h2>Files Modified</h2>
        <ol>
        <li><code>/src/mcp/tools/verbs/commands/TrainVSOMCommand.js</code> - Created (305 lines)</li>
        <li><code>/src/mcp/tools/VerbSchemas.js</code> - Added TrainVSOMSchema</li>
        <li><code>/src/mcp/tools/verbs/VerbCommandRegistry.js</code> - Registered command</li>
        <li><code>/src/mcp/tools/SimpleVerbsService.js</code> - Added to core tool names</li>
        <li><code>/src/mcp/http-server.js</code> - Added /train-vsom endpoint</li>
        <li><code>/src/frontend/vsom-standalone/public/index.html</code> - Added Train button</li>
        <li><code>/src/frontend/vsom-standalone/public/js/services/VSOMApiService.js</code> - Added trainVSOM()</li>
        <li><code>/src/frontend/vsom-standalone/public/js/vsom-standalone.js</code> - Added handleTrainVSOM()</li>
        </ol>
        <h2>Code Reuse</h2>
        <p>Successfully leveraged existing infrastructure:</p>
        <ul>
        <li>VSOMService (532 lines) - instance management, training orchestration</li>
        <li>VSOM.js (862 lines) - Kohonen algorithm implementation</li>
        <li>VSOMCore, VSOMTopology, VSOMTraining modules</li>
        </ul>
        <p><strong>No duplication</strong> - clean integration with existing architecture.</p>
        <h2>Next Steps</h2>
        <ol>
        <li><strong>User Testing</strong>: Click Train Map button with real knowledge graph data</li>
        <li><strong>Performance Tuning</strong>: Optimize for 4739+ nodes</li>
        <li><strong>Progress Indicator</strong>: Add real-time training progress updates (SSE/polling)</li>
        <li><strong>Training Options</strong>: Expose parameters in UI (epochs, learning rate, grid size)</li>
        <li><strong>Model Persistence</strong>: Cache trained positions to avoid retraining</li>
        <li><strong>Quality Metrics</strong>: Display quantization/topographic errors in UI</li>
        <li><strong>Incremental Training</strong>: Update positions when new nodes added</li>
        </ol>
        <h2>Observations</h2>
        <p><strong>User&#39;s Question Was Key</strong>: &quot;I would like you to think hard about how to make the vsom view useful for the end user. I think a Train button might be a good starting point?&quot;</p>
        <p>This simple question revealed:</p>
        <ul>
        <li>The gap between visualization UI and backend algorithms</li>
        <li>Existing infrastructure waiting to be utilized</li>
        <li>The importance of meaningful spatial organization</li>
        </ul>
        <p><strong>Code Comment Gold</strong>: The <code>// In a real VSOM...</code> comment was the Rosetta Stone that confirmed the current implementation was placeholder code.</p>
        <p><strong>Architecture Surprise</strong>: Discovering comprehensive VSOM infrastructure already implemented was a pleasant surprise. The task transformed from &quot;implement SOM algorithm&quot; to &quot;connect the dots.&quot;</p>
        <h2>Status</h2>
        <p>‚úÖ All implementation complete
        ‚úÖ Servers running (MCP: 4101, VSOM: 4103)
        ‚úÖ <strong>End-user testing SUCCESSFUL</strong></p>
        <h2>Test Results</h2>
        <p><strong>Training Execution:</strong></p>
        <ul>
        <li><strong>Nodes trained:</strong> 3,318 nodes with valid 1536-dimensional embeddings</li>
        <li><strong>Grid configuration:</strong> 20√ó20 (400 SOM cells)</li>
        <li><strong>Training epochs:</strong> 100</li>
        <li><strong>Final quantization error:</strong> 0.0503</li>
        <li><strong>Training duration:</strong> 4.3 seconds</li>
        </ul>
        <p><strong>Data Statistics:</strong></p>
        <ul>
        <li>Total interactions in system: 4,739</li>
        <li>Total concepts: 9,478 (12 unique)</li>
        <li>Session duration: 3 days 6 hours</li>
        </ul>
        <p><strong>User Experience:</strong></p>
        <ol>
        <li>Clicked &quot;üß† Train Map&quot; button</li>
        <li>Toast notification: &quot;Starting VSOM training...&quot;</li>
        <li>Training completed in ~4 seconds</li>
        <li>Visualization updated with trained spatial positions</li>
        <li>Console confirmed: <code>‚úÖ [VSOM] Training completed: {success: true}</code></li>
        </ol>
        <p><strong>Visual Result:</strong>
        The map now displays nodes in semantically meaningful positions where similar concepts cluster together. Pink/magenta clusters visible at bottom of grid show entity groupings. The transformation from arbitrary grid layout to trained semantic space is complete.</p>
        <h2>Critical Fixes Applied</h2>
        <h3>Fix #1: Correct RDF Property Path</h3>
        <p><strong>Problem:</strong> Initial query used <code>semem:hasEmbedding</code> with intermediate node structure.
        <strong>Reality:</strong> Embeddings stored directly on <code>semem:embedding</code> property as JSON array literals.
        <strong>Solution:</strong> Updated SPARQL query in TrainVSOMCommand.js:153-168.</p>
        <h3>Fix #2: VSOMService API Mismatch</h3>
        <p><strong>Problem:</strong> VSOMService.loadData() calls non-existent vsom.loadEntities() method.
        <strong>Reality:</strong> VSOM.js only provides loadFromEntities() requiring embeddingHandler.
        <strong>Solution:</strong> Bypassed VSOMService entirely, used VSOM class directly with pre-loaded embeddings.</p>
        <h3>Fix #3: Direct VSOM Population</h3>
        <p>Since embeddings are pre-loaded from SPARQL, directly populate VSOM internal arrays:</p>
        <pre><code class="language-javascript">vsom.embeddings = validNodes.map(node =&gt; node.embedding);
        vsom.entities = validNodes.map((node, index) =&gt; ({ id: node.id, index }));
        vsom.entityMetadata = validNodes.map(node =&gt; ({...}));
        </code></pre>
        <h2>Conclusion</h2>
        <p>The Train Map button is now <strong>fully functional and tested</strong>. It successfully transforms the VSOM visualization from a simple grid into a semantically meaningful knowledge space where similar concepts cluster together based on their 1536-dimensional embeddings.
         </p>
        </article>
        <p class="post-title h-cinzel">
            <a href="https://tensegrity.it/entries/2025-10-02_claude_vsom-training-implementation.html">
                Claude: VSOM Training Implementation - Making Self-Organizing Maps Useful
            </a>
        </p> <em></em>
      </div>
    </content>
  </entry>
  <entry>
    <title>Atuin : Turtle editor</title>
    <id>https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-atuin</id>
    <updated>2025-09-05T08:30:22.601Z</updated>
    <link href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-atuin" />
    <published>2025-09-05T08:30:22.601Z</published>
    <author>
      <name>Danny Ayers</name>
      <email>danny.ayers@gmail.com</email>
    </author>
    <content type="xhtml">
      <div xmlns="http://www.w3.org/1999/xhtml">
        <!-- ARTICLE CONTENT -->
        <article class="post-content">
            <h1>Atuin : Turtle editor</h1>
        <p>Needed generally.</p>
        <p>Visualization for semem</p>
        <p>2025 revision of TurtleEditor</p>
        <p>It will be a Squirt plugin</p>
        <p>First standalone</p>
        <p>On desktop, 2 panes; mobile 2 tabs</p>
        <p>What RDF model does the existing thing use? Need to use rdf-ext</p>
        <p>The graph being edited should be in local storage, but inputs/outputs should be anywhere
         </p>
        </article>
        <p class="post-title h-cinzel">
            <a href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-atuin.html">
                Atuin : Turtle editor
            </a>
        </p> <em></em>
      </div>
    </content>
  </entry>
  <entry>
    <title>Tensegrity Pivot : Namespaces</title>
    <id>https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-namespaces</id>
    <updated>2025-09-05T08:30:22.601Z</updated>
    <link href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-namespaces" />
    <published>2025-09-05T08:30:22.601Z</published>
    <author>
      <name>Danny Ayers</name>
      <email>danny.ayers@gmail.com</email>
    </author>
    <content type="xhtml">
      <div xmlns="http://www.w3.org/1999/xhtml">
        <!-- ARTICLE CONTENT -->
        <article class="post-content">
            <h1>Tensegrity Pivot : Namespaces</h1>
        <ul>
        <li>Project</li>
        <li>Lingue</li>
        <li>Zpt</li>
        <li>UM</li>
        </ul>
        <p>My conventions as instance of UM </p>
        </article>
        <p class="post-title h-cinzel">
            <a href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-namespaces.html">
                Tensegrity Pivot : Namespaces
            </a>
        </p> <em></em>
      </div>
    </content>
  </entry>
  <entry>
    <title>Tensegrity Pivot : Transmissions</title>
    <id>https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-transmissions</id>
    <updated>2025-09-05T08:30:22.601Z</updated>
    <link href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-transmissions" />
    <published>2025-09-05T08:30:22.601Z</published>
    <author>
      <name>Danny Ayers</name>
      <email>danny.ayers@gmail.com</email>
    </author>
    <content type="xhtml">
      <div xmlns="http://www.w3.org/1999/xhtml">
        <!-- ARTICLE CONTENT -->
        <article class="post-content">
            <h1>Tensegrity Pivot : Transmissions</h1>
        <h2>Meta</h2>
        <p>Need to sort out the transmissions-for-ai - actually a zpt use case!
        below</p>
        <h2>Existing better</h2>
        <p>Are workers being used?!</p>
        <ul>
        <li>Unit tests</li>
        <li>Improve integration tests</li>
        <li>Get trans-apps modules ok, tests</li>
        <li>HTTP endpoints - proxy</li>
        </ul>
        <p>Demonstration apps</p>
        <h2>New System</h2>
        <ul>
        <li>Nodeflow</li>
        <li>Electron</li>
        </ul>
        <p>Need to demo tree, graph pipelines</p>
        <p>Tree : summarisers, different chunking</p>
        <h2>New Apps</h2>
        <p>Focus on semem integration</p>
        <ul>
        <li><p>Mcp client</p>
        </li>
        <li><p>Mcp server</p>
        </li>
        <li><p>Translator - huggingface</p>
        </li>
        <li><p>Terrapack</p>
        </li>
        <li><p>Summarizer</p>
        </li>
        <li><p>Chunker</p>
        </li>
        <li><p>Rules : eye</p>
        </li>
        <li><p>PDF 2 markdown</p>
        </li>
        </ul>
        <h2>Trans for ai</h2>
        <p>Zpt allows definition of a :Cell, which can provide a :Context </p>
        <p>A context has a text representation that can be given to RAG</p>
        <ol>
        <li>Requirements</li>
        </ol>
        <p>:C = :Corpuscle</p>
        <h3></h3>
        <h3>Corpuscle: Source file</h3>
        <p>Representations :</p>
        <ul>
        <li>Label, title, desc</li>
        <li>Full source</li>
        <li>TS Types</li>
        <li>W3 interface def</li>
        <li>Jsdoc</li>
        <li>a message Processor has signature</li>
        <li>Embedding(s)</li>
        <li>Keywords</li>
        </ul>
        <h3>Corpuscle: code namespace/dir</h3>
        <p>As Source </p>
        </article>
        <p class="post-title h-cinzel">
            <a href="https://tensegrity.it/todo/tensegrity-pivot/2025-04-15_tp-transmissions.html">
                Tensegrity Pivot : Transmissions
            </a>
        </p> <em></em>
      </div>
    </content>
  </entry>
</feed>
