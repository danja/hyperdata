# [Defining Weak and Strong Agency](https://claude.ai/chat/b571cc7a-edde-4b87-a9ef-4cd8237a0cee)

c6233392-ad04-47b0-b9a0-532b812701f1

 Let me preface this by noting that since I don't have access to a live database, you should verify any specific citations I mention.

The academic discourse around AI agency tends to cluster around several key frameworks and distinctions:

1. Russell and Norvig's Framework
In their seminal AI textbook, they describe a spectrum of agency types:
- Simple reflex agents
- Model-based reflex agents
- Goal-based agents
- Utility-based agents
- Learning agents

2. "Degrees of Autonomy" Framework
This is commonly used in robotics and autonomous systems literature. Papers often reference the SAE levels of autonomy (for vehicles) as an analogy, but extend to broader AI systems.

3. Cognitive Architecture Approaches
Research stemming from groups working on cognitive architectures (like SOAR, ACT-R) often discusses different levels of agency in terms of cognitive capabilities:
- Reactive agency
- Deliberative agency
- Reflective agency
- Self-aware agency

Key papers that have influenced this discourse include:

1. Bratman's "What is intention?" (1984) - Introduced the BDI (Beliefs-Desires-Intentions) framework that influenced how we think about artificial agents

2. Franklin and Graesser's "Is it an Agent, or just a Program?: A Taxonomy for Autonomous Agents" (1996) - Provided one of the first systematic taxonomies of different types of agency

3. Castelfranchi's "Guarantees for Autonomy in Cognitive Agent Architecture" - Discussed different levels of autonomous agency

More recent work tends to focus on specific aspects of agency rather than creating overall taxonomies. Some key terms/concepts that appear frequently:

- Bounded rationality (following Herbert Simon's work)
- Mesa-optimization (from AI alignment literature)
- Instrumental agency
- Embedded agency (particularly in MIRI's research)
- Corrigible agency (in AI safety contexts)

In current research, you'll often see discussions of specific capabilities rather than overall "levels" of agency. Researchers might talk about:
- Planning depth
- Model sophistication
- Goal awareness
- Self-modification capabilities
- Meta-learning abilities

The trend seems to be moving away from rigid taxonomies toward more nuanced discussions of specific capabilities and their interactions. This reflects both the complexity of agency as a concept and our evolving understanding of AI systems.

Remember to verify any specific papers I've mentioned, as I may have made errors in the citations. Would you like me to elaborate on any of these frameworks or concepts?

---

* **dataDir** : src/applications/claude-json-converter/data
* **rootDir** : claude-json-converter
* **applicationRootDir** : claude-json-converter
* **tags** : p10.p20.p30.p40.p50
* **done** : false
* **meta** : {
  "conv_uuid": "b571cc7a-edde-4b87-a9ef-4cd8237a0cee",
  "conv_name": "Defining Weak and Strong Agency",
  "updated_at": "2024-11-07T10:36:13.381255Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/postcraft/content-raw/chat-archives/md/b571/2024-11-07_c62.md