# [Leveraging AI-Assisted Repopack for Efficient Software Development](https://claude.ai/chat/5c92e76d-870f-431c-8c52-4d939f9dc767)

394c882a-c297-4b23-b795-cac81d62dd8e

in the following a software methodology is described. Has this specific approach already got a name, maybe around Agile or Extreme programming?
tl;dr : for software projects, I'd strongly recommend repopack[^1]
Late to this thread, I was actually trying to find out if Claude has a limit on the number of Projects you can create (anyone?). Tip I must share before moving on...
I've found Claude Projects incredibly useful for not-huge (mostly coding) projects. I was using ChatGPT (and Cursor, and various free tools) but my funds are limited, and after a recent run around the block have settled on Claude Pro (and Codeium, and various free tools).
The Projects made a big difference to my productivity out of the box (well, after giving them custom system prompts), but I was still running into familiar issues around context length, also size of "project knowledge" attachments. A little breakthrough for me was discovering **repopack**. It's an open source nodejs-built utility which will crawl filesystem dirs and collate code into a single AI-friendly text file, stripping comments along the way if you like. The config is fairly basic, but it can do things like respect .gitignore, any similar custom additions etc.
The code I'm working on at the moment makes use of a few obscure libs that both OpenAI and Claude tended to hallucinate a lot over. But repopack allows me to add a couple of those of immediate interest. My main project at the moment as a whole (plus an essential lib) is over the limit. But I've been able to work around that by being selective, swapping out the "project knowledge" repopacks as I go along to focus on today's target.
A curious side effect is that it's made me much more diligent with Best Practices - favouring small, independent components and creating (with the help of AI) lots more tests than I would working alone.
Close to this is a **new methodology**  (to me at least - has it a name?), somewhere in between those ^^. My big project is a pipeliney thing which has open-ended use cases. The application functionality is defined declaratively (in RDF/Turtle), the pipeline only glued together at runtime (via a variant of dependency injection). But that gluing and runtime operation brings in a *lot* of (common) overhead. So I've begun making (with AI assistance) quick & dirty imperative-style runners for the specific applications. This gives me things that lie somewhere in between unit and (full) integration tests. It's been surprisingly useful. I'm confident the declarative bits are close to correct, so if the new single-purpose imperative runner works, there's a very good chance those components will work correctly flipped in the larger environment.   
I would have been very unlikely to go down this route otherwise, but it means I can significantly cut down the codebase an AI assistant has to consider, get it capable of much more of the work.   
[^1]: https://github.com/yamadashy/repopack

---

* **appName** : claude-json-converter
* **appPath** : claude-json-converter
* **subtask** : [undefined]
* **rootDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter
* **dataDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter/data
* **tags** : ccc10.ccc20.ccc30.ccc40.ccc50
* **done** : [undefined]
* **meta** : {
  "conv_uuid": "5c92e76d-870f-431c-8c52-4d939f9dc767",
  "conv_name": "Leveraging AI-Assisted Repopack for Efficient Software Development",
  "updated_at": "2024-09-25T15:02:28.206899Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/postcraft/content-raw/chat-archives/md/5c92/2024-09-25_394.md