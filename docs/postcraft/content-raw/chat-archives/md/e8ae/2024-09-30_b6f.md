# [Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings](https://claude.ai/chat/e8aedd30-41c9-4b31-b1cb-07a15294d1fd)

b6f5197d-6f8e-490f-a093-78047f4b672f

How might you implement topic-based chunking? What subsystems would be needed?

---

* **appName** : claude-json-converter
* **appPath** : claude-json-converter
* **subtask** : [undefined]
* **rootDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter
* **dataDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter/data
* **tags** : p10.p20.p30.p40.p50
* **done** : [undefined]
* **meta** : {
  "conv_uuid": "e8aedd30-41c9-4b31-b1cb-07a15294d1fd",
  "conv_name": "Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings",
  "updated_at": "2024-10-01T00:02:16.982765Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/postcraft/content-raw/chat-archives/md/e8ae/2024-09-30_b6f.md