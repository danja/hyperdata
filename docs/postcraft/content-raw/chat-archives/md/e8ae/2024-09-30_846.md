# [Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings](https://claude.ai/chat/e8aedd30-41c9-4b31-b1cb-07a15294d1fd)

84608f9c-cf94-45cc-b170-282c127936a0

How would you decide on a chunking method in this scenario?

---

* **appName** : claude-json-converter
* **appPath** : claude-json-converter
* **subtask** : [undefined]
* **rootDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter
* **dataDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter/data
* **tags** : p10.p20.p30.p40.p50
* **done** : [undefined]
* **meta** : {
  "conv_uuid": "e8aedd30-41c9-4b31-b1cb-07a15294d1fd",
  "conv_name": "Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings",
  "updated_at": "2024-10-01T00:02:16.982765Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/postcraft/content-raw/chat-archives/md/e8ae/2024-09-30_846.md