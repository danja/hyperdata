# [Integrating Process Return Status in Application Tests](https://claude.ai/chat/b32e6d95-f40f-4642-b5c9-c6f969c7cc55)

d346137e-d8a4-4a7e-98a0-a72acbdb3450

 

<antArtifact identifier="test-apps-spec" type="application/vnd.ant.code" language="javascript" title="Enhanced test_apps.spec.js with improved diagnostics">
import path from 'path'
import { fileURLToPath } from 'url'
import { expect } from 'chai'
import { exec } from 'child_process'
import fs from 'fs/promises'
import { glob } from 'glob'
import { existsSync } from 'fs'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)
const rootDir = path.resolve(__dirname, '../../')

async function runCommand(command, options) {
    return new Promise((resolve, reject) => {
        const startTime = process.hrtime()
        
        exec(`./trans ${command}`, { ...options, cwd: rootDir }, (error, stdout, stderr) => {
            const endTime = process.hrtime(startTime)
            const duration = (endTime[0] + endTime[1] / 1e9).toFixed(3)
            
            const result = {
                stdout,
                stderr,
                error: error ? {
                    code: error.code,
                    signal: error.signal,
                    stack: error.stack
                } : null,
                success: !error,
                duration
            }
            resolve(result)
        })
    })
}

describe('Application Integration Tests', function () {
    it('should run test applications', async function () {
        const testApps = await glob(path.join(rootDir, 'src/applications/test_*'))
        expect(testApps.length).to.be.greaterThan(0)

        for (const appDir of testApps) {
            const appName = path.basename(appDir)
            console.log(`\nTesting ${appName}`)

            const configPath = path.join(appDir, 'test-config.json')
            const config = existsSync(configPath) ?
                JSON.parse(await fs.readFile(configPath, 'utf8')) :
                { transmissions: [{ name: appName }] }

            for (const tx of config.transmissions) {
                let cmd = tx.name
                if (tx.message) cmd += ` -m '${JSON.stringify(tx.message)}'`

                const result = await runCommand(cmd)
                
                if (!result.success) {
                    console.error('\n' + '='.repeat(80))
                    console.error(`ðŸ”´ Test failed for ${cmd}`)
                    console.error('='.repeat(80))
                    console.error('\nExecution Details:')
                    console.error('-'.repeat(40))
                    console.error(`Duration: ${result.duration}s`)
                    console.error('Exit code:', result.error?.code)
                    console.error('Signal:', result.error?.signal)
                    
                    console.error('\nError Stack:')
                    console.error('-'.repeat(40))
                    console.error(result.error?.stack)
                    
                    console.error('\nStderr Output:')
                    console.error('-'.repeat(40))
                    console.error(result.stderr || '(no stderr output)')
                    
                    console.error('\nStdout Output:')
                    console.error('-'.repeat(40))
                    console.error(result.stdout || '(no stdout output)')
                    
                    console.error('\nTest Configuration:')
                    console.error('-'.repeat(40))
                    console.error(JSON.stringify(tx, null, 2))
                    console.error('\n' + '='.repeat(80))

                    // Try to preserve outputs for failed tests
                    try {
                        const failuresDir = path.join(rootDir, 'test-failures', appName, new Date().toISOString())
                        await fs.mkdir(failuresDir, { recursive: true })
                        await fs.writeFile(
                            path.join(failuresDir, 'test-output.json'), 
                            JSON.stringify({ result, config: tx }, null, 2)
                        )
                        console.error(`Failure details saved to: ${failuresDir}`)
                    } catch (err) {
                        console.error('Failed to save failure details:', err)
                    }
                } else {
                    console.log(`âœ… ${cmd} completed successfully (${result.duration}s)`)
                }

                expect(result.success, `Command failed: ${cmd}`).to.be.true

                if (tx.requiredFiles) {
                    for (const pattern of tx.requiredFiles) {
                        const outputFiles = await glob(path.join(appDir, 'data/output', pattern))
                        for (const outputFile of outputFiles) {
                            const requiredFile = outputFile.replace('output-', 'required-')
                            const [output, required] = await Promise.all([
                                fs.readFile(outputFile, 'utf8'),
                                fs.readFile(requiredFile, 'utf8')
                            ])
                            expect(output.trim()).to.equal(required.trim())
                        }
                    }
                }
            }
        }
    })
})
</antArtifact>

This enhanced version includes:
1. Execution timing for each test
2. Structured error output with clear section separators
3. Automatic preservation of failure details in timestamped directories
4. Better visual formatting of success/failure indicators

Let me know if you'd like me to clarify any part of the implementation.

q1: Should we add a cleanup function for the test-failures directory?
q2: Would it be useful to add memory usage tracking?
q3: Should we add configuration for the maximum number of preserved failures?
q4: Should we capture environment variables in the failure output?

---

* **appName** : claude-json-converter
* **appPath** : claude-json-converter
* **subtask** : [undefined]
* **rootDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter
* **dataDir** : /home/danny/github-danny/transmissions/src/applications/claude-json-converter/data
* **tags** : ccc10.ccc20.ccc30.ccc40.ccc50
* **done** : [undefined]
* **meta** : {
  "conv_uuid": "b32e6d95-f40f-4642-b5c9-c6f969c7cc55",
  "conv_name": "Integrating Process Return Status in Application Tests",
  "updated_at": "2024-11-28T17:41:13.290304Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/postcraft/content-raw/chat-archives/md/b32e/2024-11-28_d34.md