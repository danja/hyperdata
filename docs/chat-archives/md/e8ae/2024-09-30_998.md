# Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings

e8aedd30-41c9-4b31-b1cb-07a15294d1fd

99880054-80b5-4a5d-aad5-487a7b0d71a2

How can an tokenizer and vector embedding be combined efficiently to provide semantic search, data for llm fine tuning as well as rag afterwards?

---

* **dataDir** : src/applications/claude-json-converter/data
* **rootDir** : claude-json-converter
* **applicationRootDir** : claude-json-converter
* **tags** : p10.p20.p30.p40.p50
* **done** : false
* **meta** : {
  "conv_uuid": "e8aedd30-41c9-4b31-b1cb-07a15294d1fd",
  "conv_name": "Efficient Semantic Search and LLM Fine-Tuning with Tokenizers and Embeddings",
  "updated_at": "2024-10-01T00:02:16.982765Z"
}
* **filepath** : /home/danny/github-danny/hyperdata/docs/chat-archives/md/e8ae/2024-09-30_998.md